---
title: "project_part_3"
author: "Annie Zhu"
date: "2023-03-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(boot)
library(glmnet)
library(dplyr)
```

## Prediction on test set

First we need to import all the data. The giant block of code below generates 6 data frames:
1) regression_train_data.  
2) classification_train_data.  
3) regression_val_data.  
4) classification_val_data.  
5) regression_test_data.  
6) classification_test_data.  

Let's use this block to define functions used in the next block.
```{r functions}
## Defining a function for transformations
transformations <- function(val_data) {
  ## changing the column names
  basic_attributes <- c("total_before", "before_24hr", "from_48hr_to_24hr", "first_24hr", "change_between_two_days")
  prefix <- c("avg", "sd", "min", "max", "med")
  suffix <- c("comments", "links")
  for (i in 1:5){
    for (j in 1:2) {
      for (k in 1:5) {
        index = 10 * (i-1) + 5 * (j-1) + k
        colnames(val_data)[index] <- paste(prefix[k], basic_attributes[i], suffix[j], sep = "_")
      }
    }
  }
  
  for (i in 1:5){
    for (j in 1:2) {
      index = 50 + i + 5 * (j-1)
      colnames(val_data)[index] <- paste(basic_attributes[i], suffix[j], sep = "_")
    }
  }
  
  colnames(val_data)[61] <- "time_length"
  colnames(val_data)[62] <- "post_length"
  for (i in 1: 200){
    index = toString(i)
    colnames(val_data)[i + 62] <- paste("freq_word_feature_", index, sep = "")
  }
  
  days <- c("mon", "tues", "wed", "thurs", "fri", "sat", "sun")
  for (i in 1:7) {
    colnames(val_data)[i + 262] <- paste("basetime", days[i], sep = "_")
  }
  for (i in 1:7) {
    colnames(val_data)[i + 269] <- paste("publication", days[i], sep = "_")
  }
  
  colnames(val_data)[277] <- "parent_pages_count"
  colnames(val_data)[278] <- "min_parent_pages_comments"
  colnames(val_data)[279] <- "max_parent_pages_comments"
  colnames(val_data)[280] <- "avg_parent_pages_comments"
  colnames(val_data)[281] <- "after_24hr_comments"
  return(val_data)
}

## Defining a function for classification data specifically
classification <- function(data) {
  classification_data <- data %>%
    mutate(difference_in_ROG = (after_24hr_comments - before_24hr_comments) - change_between_two_days_comments) %>%
    mutate(direction_of_growth = ifelse(difference_in_ROG<0, 0, 1)) %>%
    select(-c(difference_in_ROG, after_24hr_comments, min_before_24hr_comments, 
              min_before_24hr_links, min_first_24hr_comments, min_first_24hr_links, 
              min_change_between_two_days_comments, change_between_two_days_comments,change_between_two_days_links))
  classification_data$direction_of_growth = as.factor(classification_data$direction_of_growth)
  return(classification_data)
}

```

Now we import all the data to form train, validation, and test sets for both the regression task and the classification task.

```{r testing}
# importing data
data <- read_csv("./trainingData.csv", show_col_types = FALSE)
regression_train_data <- data
classification_train_data <- classification(data)

# validation data
val_data <- read_csv("./BlogFeedback/blogData_test-2012.02.01.00_00.csv",  col_names = FALSE, show_col_types = FALSE)
numbers <- seq(1, 31)
numbers <- sprintf("%02d", numbers)
for (i in 2:29) {
  path_name <- paste("./BlogFeedback/blogData_test-2012.02.", numbers[i],  ".00_00.csv", sep = "")
  new_data <- read_csv(path_name, col_names = FALSE, show_col_types = FALSE)
  val_data <- rbind(val_data, new_data)
}
new_data <- read_csv("./BlogFeedback/blogData_test-2012.03.01.00_00.csv", col_names = FALSE, show_col_types = FALSE)
val_data <- rbind(val_data, new_data)
val_data <- transformations(val_data)
regression_val_data <- val_data
classification_val_data <- classification(val_data)

# testing data
test_data <- read_csv("./BlogFeedback/blogData_test-2012.03.02.00_00.csv",  col_names = FALSE, show_col_types = FALSE)
numbers <- seq(1, 31)
numbers <- sprintf("%02d", numbers)
for (i in 3:25) {
  path_name <- paste("./BlogFeedback/blogData_test-2012.03.", numbers[i],  ".00_00.csv", sep = "")
  new_data <- read_csv(path_name, col_names = FALSE, show_col_types = FALSE)
  test_data <- rbind(test_data, new_data)
}
for (i in 26:31) {
  path_name <- paste("./BlogFeedback/blogData_test-2012.03.", numbers[i],  ".01_00.csv", sep = "")
  new_data <- read_csv(path_name, col_names = FALSE, show_col_types = FALSE)
  test_data <- rbind(test_data, new_data)
}
regression_test_data <- transformations(test_data)
classification_test_data <- classification(regression_test_data)
```

Let's do a sanity check via printing.
```{r checking}
# printing everything to check if its what we want
print(regression_train_data)
print(classification_train_data)
print(regression_val_data)
print(classification_val_data)
print(regression_test_data)
print(classification_test_data)
```

Now let's re-generate the best performing model on the classification task.
```{r train}
new_model <- glm(direction_of_growth ~ . + time_length*total_before_comments + 
                   time_length*before_24hr_comments + 
                   time_length*from_48hr_to_24hr_comments +
                   time_length*first_24hr_comments +
                   med_before_24hr_comments*before_24hr_comments + 
                   med_before_24hr_comments*from_48hr_to_24hr_comments +
                   med_first_24hr_comments*before_24hr_comments+
                   med_first_24hr_comments*from_48hr_to_24hr_comments, 
                 data=classification_train_data, family = "binomial")
# print(new_model)
```


Lastly, we can do evaluation of the classification task on the test set.
```{r test}
# Prediction
p1<-predict(new_model, classification_test_data, 
            type = 'response')

# confusion Matrix 
pre1<-ifelse(p1 > 0.5, 1, 0)
table<-table(Prediction = pre1, 
             Actual = classification_test_data$direction_of_growth) 
print(table)

# getting the metrics
TN = table[1]
FP = table[2]
FN = table[3]
TP = table[4]
accuracy = (TP + TN) / nrow(classification_test_data)
loss = 1 - accuracy
TPR = TP / (TP + FN)
FPR = FP / (FP + TN)

print("")
print(paste("The 0-1 loss is", loss))
print(paste("The accuracy is", accuracy))
```
Our generalization error based on the testing set is 0.107. In comparison, our estimated prediction for the generalized error was 0.105 so we were very close with our estimate!

## Linear Regression Model 
Here is the output for running our baseline model.

```{r regression}
model1 <- lm(after_24hr_comments ~ . , data=regression_train_data)
summary(model1)
```

## Significant Coefficients

```{r narrowing}
# these are our significant coefficients 
r_coeffs <- as.data.frame(summary(model1)$coefficients)
colnames(r_coeffs)[4] ="pvalue"
colnames(r_coeffs)[2] ="stderror"
r_sig_coeffs <- r_coeffs %>% filter(pvalue < 0.001)
arrange(r_sig_coeffs, pvalue)

# print(row.names(r_sig_coeffs))
x = ""
for (i in 1:nrow(r_sig_coeffs)){
  x = paste(x, paste(row.names(r_sig_coeffs)[i], ", ", sep = ""), sep = "")
}
# print(x)
```

## Collinearity 
```{r standarderror}
print(median(r_coeffs$stderror))
bag_of_words = r_coeffs %>% slice(57:233)
print(median(bag_of_words$stderror))

arrange(r_coeffs, desc(stderror))
hist(r_coeffs$stderror, xlab = 'Standard Error for Coefficients', ylab = 'Frequency', main = 'Standard Error of Coefficient Values', breaks = 20)

```

## Sig Coefficients for Test Data

```{r withtest}
model2 <- lm(after_24hr_comments ~ . , data=regression_test_data)
# these are our significant coefficients 
r_coeffs_test <- as.data.frame(summary(model2)$coefficients)
colnames(r_coeffs_test)[4] ="pvalue"
colnames(r_coeffs_test)[2] ="stderror"
r_sig_coeffs_test <- r_coeffs_test %>% filter(pvalue < 0.001)
arrange(r_sig_coeffs_test, pvalue)

# print(row.names(r_sig_coeffs))
x = ""
for (i in 1:nrow(r_sig_coeffs_test)){
  x = paste(x, paste(row.names(r_sig_coeffs_test)[i], ", ", sep = ""), sep = "")
}
print(x)


```

## Bonferroni Correction
```{r bonferroni}
bon_sig_coeffs <- r_coeffs %>% filter(pvalue < 0.00000355871)
print(bon_sig_coeffs)

```

## Benjamini-Hochberg 

We are going to implement the Benjamini-Hochberg procedure.

```{r significance}
# Function to perform Benjamini-Hochberg procedure on p-values
bh.adjust <- function(pvals, alpha=0.001) {
  # Get number of hypotheses tested
  m <- length(pvals)
  
  # Calculate Benjamini-Hochberg critical values
  k <- 1:m
  crit <- alpha * k / m
  
  # Sort p-values in ascending order
  sorted_pvals <- sort(pvals)
  
  # Find the largest index k such that p[k] <= crit[k]
  index <- max(which(sorted_pvals <= crit))
  
  # Adjust p-values using the largest index
  adj_pvals <- pvals * m / index
  
  # Return adjusted p-values
  return(adj_pvals)
}


# Calculate p-values for coefficients
pvals <- summary(model1)$coefficients[,4]

# Perform Benjamini-Hochberg procedure on p-values
adj_pvals <- bh.adjust(pvals)

# Filter significant coefficients
coeffs <- as.data.frame(summary(model1)$coefficients)
sig_coeffs <- cbind(coeffs, adj_pvals) %>% filter(adj_pvals <= 0.001)


# Print significant coefficients
print(sig_coeffs)
x = ""
for (i in 1:nrow(sig_coeffs)){
  x = paste(x, paste(row.names(sig_coeffs)[i], ", ", sep = ""), sep = "")
}
print(x)

```



## Bootstrapping 
Let's bootstrap to estimate the confidence intervals for the regression coefficients. 

```{r bootstrap}
coef.boot = function(data, indices) {
  fm = lm(data = data[indices,], after_24hr_comments ~ .)
  return(coef(fm))
}
boot.out = boot(regression_train_data, coef.boot, 1000)
```

Visualizing and interpreting the output.
```{r outputboot}
plot(boot.out)

simulated_data = as.data.frame(boot.out$t)
print(simulated_data)
```


```{r visualbootstrap}
# 

hist(simulated_data$V53, xlab = 'Coefficent values for before_24hr_comments variable', ylab = 'Frequency', main = 'Bootstrapped Coefficient Values')
hist(simulated_data$V54, xlab = 'Coefficent values for from_48hr_to_24hr_comments variable', ylab = 'Frequency', main = 'Bootstrapped Coefficient Values')
hist(simulated_data$V62, xlab = 'Coefficent values for time_length variable', ylab = 'Frequency', main = 'Bootstrapped Coefficient Values')
```


```{r confidenceinterval}
compute_confidence_interval <- function(vec, name) {
  # Set values
  est <- model1$coefficients[name]  # Point estimate
  se <- sd(vec)   # Standard error
  alpha <- 0.05  # Significance level
  
  # Compute critical value
  cv <- qt(1 - alpha/2, df = Inf)
  
  # Compute confidence interval
  ci_lower <- est - cv * se
  ci_upper <- est + cv * se
  
  # Print results
  cat("Confidence interval for", name, "is : [", ci_lower, ", ", ci_upper, "]\n")
  
}

r_confidence_interval <- function(name) {
  # Set values
  est <- model1$coefficients[name]  # Point estimate
  se <- sqrt(diag(vcov(model1)))[name]   # Standard error
  alpha <- 0.05  # Significance level
  
  # Compute critical value
  cv <- qt(1 - alpha/2, df = Inf)
  
  # Compute confidence interval
  ci_lower <- est - cv * se
  ci_upper <- est + cv * se
  
  # Print results
  cat("Confidence interval for", name, "is : [", ci_lower, ", ", ci_upper, "]\n")
}

print("Bootstrapped Confidence Intervals")
compute_confidence_interval(simulated_data$V53, "before_24hr_comments")
compute_confidence_interval(simulated_data$V54, "from_48hr_to_24hr_comments")
compute_confidence_interval(simulated_data$V62, "time_length")

print("R Regression Confidence Intervals")
r_confidence_interval("before_24hr_comments")
r_confidence_interval("from_48hr_to_24hr_comments")
r_confidence_interval("time_length")

```

Summary statistics on this section:

```{r summarybootstrap}
bootstrapped_SE <- apply(simulated_data,2,sd)
standard_r_SE <- sqrt(diag(vcov(model1)))
difference_in_SE <- (bootstrapped_SE - standard_r_SE) / standard_r_SE
hist(difference_in_SE, xlab = 'Proportional difference in SE Estimate', ylab = 'Frequency', main = 'Comparing SE for Bootstrap and Standard R', breaks = 14)

bootstrapped_SE['V12']
standard_r_SE['avg_before_24hr_comments']
difference_in_SE['avg_before_24hr_comments']

bootstrapped_SE['V32']
standard_r_SE['avg_first_24hr_comments']
difference_in_SE['avg_first_24hr_comments']


```

Here is some code to export the bootstrapped coefficient values.

```{r export}
# export the data so that I don't have to rerun the 30min+ long bootstrap function everytime
write.csv(simulated_data, "./bootstrap.csv", row.names=FALSE)

```


## Subset of Covariates

Here we look at the sig coeff for just a subset of covariates used to train the model.

```{r subset}
Xtrain = select(regression_train_data, -c(after_24hr_comments)) %>% data.matrix()
Ytrain = regression_train_data$after_24hr_comments
model_lasso <- glmnet(x = Xtrain, y = Ytrain, alpha = 1, lambda = 0.5)

# TRAIN lm() without 0-covariates
train_X_covariates <- as.matrix(coef(model_lasso))
X_rows <- rownames(train_X_covariates)[train_X_covariates != 0]
X_rows <- X_rows[!X_rows == "(Intercept)"]
Xtrain <- Xtrain[,X_rows]
colnames(Xtrain)
model_lasso_new <- lm(Ytrain ~ Xtrain, data=regression_train_data)
summary(model_lasso_new)

```

## Significant Coefficients for Lasso-ed Model

```{r sigcoeff_lasso}

# these are our significant coefficients 
r_coeffs_lasso <- as.data.frame(summary(model_lasso_new)$coefficients)
colnames(r_coeffs_lasso)[4] ="pvalue"
colnames(r_coeffs_lasso)[2] ="stderror"
r_sig_coeffs_lasso <- r_coeffs_lasso %>% filter(pvalue < 0.001)
arrange(r_sig_coeffs_lasso, pvalue)

# print(row.names(r_sig_coeffs))
x = ""
for (i in 1:nrow(r_sig_coeffs_lasso)){
  x = paste(x, paste(row.names(r_sig_coeffs_lasso)[i], ", ", sep = ""), sep = "")
}
print(x)
```





The End

~~~
